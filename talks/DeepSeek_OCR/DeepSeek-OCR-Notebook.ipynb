{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 探索 DeepSeek-OCR\n",
        "\n",
        "> 日期：2025/10/21\n",
        "\n",
        "<a href=\"https://www.tenlong.com.tw/products/9786264142915\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
        "\n",
        "## 👨‍💻 作者資源與聯絡方式\n",
        "\n",
        "### 📚 深度學習專書\n",
        "**📖 《LangGraph 實戰開發 AI Agent 全攻略》** - 我的最新技術著作\n",
        "深入探討 LangGraph、Agentic AI System 等前沿技術\n",
        "**[立即購買](https://www.tenlong.com.tw/products/9786264142915)**\n",
        "\n",
        "### 🌐 社群媒體與技術交流\n",
        "如果您有任何疑問或想要進一步交流，歡迎透過以下管道聯絡：\n",
        "\n",
        "* **📖 技術專書**： [購買我的 LangGraph 實戰開發 AI Agent 全攻略](https://www.tenlong.com.tw/products/9786264142915)\n",
        "* **💻 GitHub**： [我的開源專案](https://github.com/Heng-xiu)\n",
        "* **🤗 Hugging Face**： [我的模型與資料集](https://huggingface.co/Heng666)\n",
        "* **✍️ 部落格**： [技術文章分享](https://r23456999.medium.com/)\n",
        "\n",
        "感謝大家的支持！期待與更多 AI 技術愛好者交流討論 🚀\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://ko-fi.com/hengshiousheu\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a>\n",
        "</div>\n",
        "\n",
        "<a href=\"https://www.tenlong.com.tw/products/9786264142915\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
        "\n"
      ],
      "metadata": {
        "id": "6TBKBHJmyv-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 第一章、DeepSeek-OCR\n",
        "DeepSeek 表示，DeepSeek-OCR 模型是透過光學二維映射技術壓縮長文字情境可行性的初步探索。\n",
        "\n",
        "此模型主要由 DeepEncoder 和 DeepSeek3B-MoE-A570M 解碼器兩大核心組件構成。其中 DeepEncoder 作為核心引擎，既能維持高解析度輸入下的低啟動狀態，又能實現高壓縮比，進而產生數量適中的視覺 token。\n",
        "\n",
        "實驗數據顯示，當文字 token 數量在視覺 token 的 10 倍以內（即壓縮率<10×）時，模型的解碼（OCR）精度可達97%；即使在壓縮率達到20× 的情況下，OCR 準確率仍維持在約60%。\n",
        "\n",
        "> 這項結果顯示出該方法在長上下文壓縮和 LLM 的記憶遺忘機制等研究方向上具有相當潛力。\n",
        "---"
      ],
      "metadata": {
        "id": "xKYZ6q4yud1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 第二章：環境建置與前置準備\n",
        "在我們開始微調 Whisper 之前，首先要確保我們的開發環境已經準備就緒。一個穩定且配置正確的環境是成功訓練模型的第一步。\n",
        "\n",
        "> GPU 啟用： 請確保您的 Colab Notebook 已啟用 GPU。點擊菜單欄的 執行階段 (Runtime) -> 變更執行階段類型 (Change runtime type)，然後在 硬體加速器 (Hardware accelerator) 中選擇 GPU。"
      ],
      "metadata": {
        "id": "kEjFOe3Subau"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c65ccf",
        "outputId": "1041eb4a-e931-48b6-8d41-1bf7af5fa818"
      },
      "source": [
        "%pip install --quiet addict\n",
        "%pip install --quiet transformers==4.46.3\n",
        "%pip install --quiet tokenizers==0.20.3\n",
        "%pip install --quiet PyMuPDF\n",
        "%pip install --quiet img2pdf\n",
        "%pip install --quiet einops\n",
        "%pip install --quiet easydict\n",
        "%pip install --quiet addict\n",
        "%pip install --quiet Pillow\n",
        "%pip install --quiet numpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for img2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1 首先，來登入 HuggingFace\n",
        "\n",
        "本章節我們先確認在本實驗環境中，可以獲取到 HuggingFace 資源，包含下載資料集、模型等操作\n",
        "\n",
        "您可以在 Hugging Face Hub 中找到您的 [Hugging Face token](https://huggingface.co/login?next=%2Fsettings%2Ftokens)\n"
      ],
      "metadata": {
        "id": "hbLWfLbIuj3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "api = HfApi(token=HF_TOKEN)\n",
        "username = api.whoami()['name']\n",
        "print(username)"
      ],
      "metadata": {
        "id": "0v5K0OLRulUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 GPU 驅動與 CUDA 支援確認\n",
        "\n",
        "LLM 的訓練需要大量的計算資源，幾乎必須仰賴 GPU (Graphics Processing Unit)。因此，確認您的環境是否正確偵測到 GPU 並支援 CUDA 是至關重要的一步。\n",
        "\n",
        "CUDA 是 NVIDIA 提供的平行運算平台和程式設計模型，允許軟體使用 GPU 進行通用計算。PyTorch (一個流行的深度學習框架) 透過 CUDA 來利用 NVIDIA GPU 的運算能力。\n",
        "\n",
        "請執行以下 Python 程式碼，檢查您的 PyTorch 環境是否已正確偵測到 CUDA："
      ],
      "metadata": {
        "id": "QyCjjMaaummZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch 是否支援 CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"目前使用的 CUDA 裝置名稱: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA 裝置數量: {torch.cuda.device_count()}\")\n",
        "    # 可以進一步檢查 CUDA 版本\n",
        "    print(f\"PyTorch 編譯的 CUDA 版本: {torch.version.cuda}\")\n",
        "    # 執行 nvidia-smi (僅限 Linux/Windows 終端機，Colab 可直接執行)\n",
        "    # !nvidia-smi\n",
        "else:\n",
        "    print(\"警告：未偵測到 CUDA。模型訓練將在 CPU 上運行，速度會非常慢。\")\n",
        "    print(\"請檢查您的 GPU 驅動程式安裝、CUDA Toolkit 設定以及 PyTorch 的 CUDA 支援。\")"
      ],
      "metadata": {
        "id": "zdkH-aZmupAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#第三章、玩玩 DeepSeek-OCR"
      ],
      "metadata": {
        "id": "mJPB-CfDuogo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 拿到預訓練模型：輕鬆載入 DeepSeek-OCR\n"
      ],
      "metadata": {
        "id": "7sT7eQ89vMVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet flash-attn==2.7.3 --no-build-isolation"
      ],
      "metadata": {
        "id": "cS7sAgHsvFFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etlzUFnV9RPD",
        "outputId": "a0b6d746-5f95-429d-9213-915f17e6e834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of DeepseekOCRForCausalLM were not initialized from the model checkpoint at deepseek-ai/DeepSeek-OCR and are newly initialized: ['model.vision_model.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "model_name = 'deepseek-ai/DeepSeek-OCR'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_name,\n",
        "    _attn_implementation='eager', #attn_implementation=\"flash_attention_2\" # 記得要額外安裝才能使用且只支持 Ampere GPUs\n",
        "    trust_remote_code=True,\n",
        "    use_safetensors=True\n",
        "    )\n",
        "model = model.eval().cuda().to(torch.bfloat16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#第四章、各類提示語測試\n",
        "\n",
        "DeepSeek-OCR 提供多種 **Prompt 模式**，可針對不同應用情境（純文字擷取、文件結構保留、座標輸出、影像描述等）進行最佳化。\n",
        "選擇不同 Prompt 將影響：\n",
        "\n",
        "* 輸出格式（純文字、Markdown、座標資訊、描述）\n",
        "* 處理時間\n",
        "* 適用場景\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 四大 Prompt 模式總覽\n",
        "\n",
        "| Prompt 名稱                | 語法                                        | 最佳用途                | 輸出格式                                | 推論時間               |                  |        |       |     |        |        |\n",
        "| ------------------------ | ----------------------------------------- | ------------------- | ----------------------------------- | ------------------ | ---------------- | ------ | ----- | --- | ------ | ------ |\n",
        "| **Free OCR** ⭐（推薦）       | `<image>\\nFree OCR.`                      | 一般文字擷取、文件或文章、乾淨可讀輸出 | 純文字                                 | 約 24 秒             |                  |        |       |     |        |        |\n",
        "| **Markdown**             | `<image>\\n<                               | grounding           | >Convert the document to markdown.` | 具結構的文件、保留段落與標題格式   | Markdown 格式（含結構） | 約 39 秒 |       |     |        |        |\n",
        "| **Grounding OCR**        | `<image>\\n<                               | grounding           | >OCR this image.`                   | 需文字位置、做 UI 標註、文件分析 | 文字＋座標 (`<        | ref    | >...< | det | >...`) | 約 58 秒 |\n",
        "| **Detailed Description** | `<image>\\nDescribe this image in detail.` | 圖像理解、內容分析、非OCR主用途   | 詳細描述文字                              | 約 9 秒              |                  |        |       |     |        |        |\n"
      ],
      "metadata": {
        "id": "hsSPamrLsv6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt：**\n",
        "\n",
        "```python\n",
        "prompt = \"<image>\\nFree OCR.\"\n",
        "```\n",
        "\n",
        "**最佳用途：**\n",
        "\n",
        "* 一般文字擷取\n",
        "* 乾淨、可讀性高的輸出\n",
        "* 適合文章與文件\n",
        "\n",
        "**輸出格式：**\n",
        "\n",
        "* 純文字、自然段落流暢\n",
        "* 最快且最穩定\n",
        "\n",
        "**範例：**\n",
        "\n",
        "```\n",
        "# The perils of vibe coding\n",
        "\n",
        "Elaine Moore\n",
        "\n",
        "new OpenAI model arrived this month...\n",
        "```"
      ],
      "metadata": {
        "id": "aqfQz9ydqciL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Free OCR（推薦）"
      ],
      "metadata": {
        "id": "Op-QAEDvtHyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"<image>\\nFree OCR.\"\n",
        "image_file = '/content/OCRTest.png'\n",
        "output_path = '/content/'\n",
        "\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY_Pd4qQqfkv",
        "outputId": "153f5f95-66a5-459a-a71d-87c655e54455"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "| Period Ending | Dec 31, 2008 | Dec 31, 2009 | Dec 31, 2010 |\n",
            "|--------------|--------------|--------------|--------------|\n",
            "| **Assets**    |              |              |              |\n",
            "| **Current Assets** |              |              |              |\n",
            "| Cash And Cash Equivalents | 8,656,672 | 10,198,000 | 13,630,000 |\n",
            "| Short Term Investments | 7,189,099 | 14,287,000 | 21,345,000 |\n",
            "| Net Receivables | 2,928,297 | 3,845,000 | 5,261,000 |\n",
            "| Inventory | - | - | - |\n",
            "| Other Current Assets | 1,404,114 | 837,000 | 1,326,000 |\n",
            "| **Total Current Assets** | 20,178,182 | 29,167,000 | 41,562,000 |\n",
            "| **Long Term Investments** | 85,160 | 129,000 | 523,000 |\n",
            "| Property Plant and Equipment | 5,233,843 | 4,845,000 | 7,759,000 |\n",
            "| Goodwill | 4,839,854 | 4,903,000 | 6,256,000 |\n",
            "| Intangible Assets | 996,690 | 775,000 | 1,044,000 |\n",
            "| Accumulated Amortization | - | - | - |\n",
            "| Other Assets | 433,846 | 415,000 | 442,000 |\n",
            "| Deferred Long Term Asset Charges | - | 263,000 | 265,000 |\n",
            "| **Total Assets** | 31,767,575 | 40,497,000 | 57,851,000 |\n",
            "\n",
            "| **Liabilities** |              |              |              |\n",
            "| **Current Liabilities** |              |              |              |\n",
            "| Accounts Payable | 2,084,006 | 2,462,000 | 6,137,000 |\n",
            "| Short/Current Long Term Debt | - | - | 3,465,000 |\n",
            "| Other Current Liabilities | 218,084 | 285,000 | 394,000 |\n",
            "| **Total Current Liabilities** | 2,302,090 | 2,747,000 | 9,996,000 |\n",
            "| Long Term Debt | 890,115 | - | - |\n",
            "| Other Liabilities | 294,175 | 1,704,000 | 1,579,000 |\n",
            "| Deferred Long Term Liability Charges | 42,333 | 42,000 | 35,000 |\n",
            "| Minority Interest | - | - | - |\n",
            "| Negative Goodwill | - | - | - |\n",
            "| **Total Liabilities** | 3,528,713 | 4,493,000 | 11,610,000 |\n",
            "\n",
            "| **Stockholders' Equity** |              |              |              |\n",
            "| **Misc Stocks Options Warrants** | - | - | - |\n",
            "| Redeemable Preferred Stock | - | - | - |\n",
            "| Preferred Stock | - | - | - |\n",
            "| Common Stock | 315 | 15,817,000 | 18,235,000 |\n",
            "| Retained Earnings | 13,561,630 | 20,082,000 | 27,868,000 |\n",
            "| Treasury Stock | - | - | - |\n",
            "| Capital Surplus | 14,450,338 | - | - |\n",
            "| Other Stockholder Equity | 226,579 | 105,000 | 138,000 |\n",
            "| **Total Stockholder Equity** | 28,238,862 | 36,004,000 | 46,241,000 |\n",
            "==================================================\n",
            "image size:  (768, 1024)\n",
            "valid image tokens:  792\n",
            "output texts tokens (valid):  785\n",
            "compression ratio:  0.99\n",
            "==================================================\n",
            "===============save results:===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Markdown 模式\n",
        "\n",
        "**Prompt：**\n",
        "\n",
        "```python\n",
        "prompt = \"<image>\\n<|grounding|>Convert the document to markdown.\"\n",
        "```\n",
        "\n",
        "**最佳用途：**\n",
        "\n",
        "* 結構化文件（含標題、段落、圖片）\n",
        "* 需保留 Markdown 格式者\n",
        "\n",
        "**輸出格式：**\n",
        "\n",
        "* 含標題 `##`、圖片 `![]()`、座標資訊\n",
        "* 結構化 Markdown\n",
        "\n",
        "**範例：**\n",
        "\n",
        "```markdown\n",
        "## The perils of vibe coding\n",
        "TECHNOLOGY\n",
        "Elaine Moore\n",
        "![](images/0.jpg)\n",
        "new OpenAI model arrived...\n",
        "```"
      ],
      "metadata": {
        "id": "ZgXZYgJmqU4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
        "image_file = '/content/OCRTest.png'\n",
        "output_path = '/content/'\n",
        "\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQlgsDMn9c8p",
        "outputId": "30f9c15b-1f99-4c86-f49d-8e747958a927"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
            "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "<|ref|>title<|/ref|><|det|>[[81, 70, 350, 96]]<|/det|>\n",
            "# Google Inc. (GOOG)  \n",
            "\n",
            "<|ref|>title<|/ref|><|det|>[[81, 101, 220, 119]]<|/det|>\n",
            "# Balance Sheet  \n",
            "\n",
            "<|ref|>text<|/ref|><|det|>[[588, 103, 797, 119]]<|/det|>\n",
            "All numbers in thousands  \n",
            "\n",
            "<|ref|>table<|/ref|><|det|>[[77, 139, 844, 465]]<|/det|>\n",
            "\n",
            "<table><tr><td>Period Ending</td><td>Dec 31, 2008</td><td>Dec 31, 2009</td><td>Dec 31, 2010</td></tr><tr><td>Assets</td><td></td><td></td><td></td></tr><tr><td>Current Assets</td><td></td><td></td><td></td></tr><tr><td>Cash And Cash Equivalents</td><td>8,656,672</td><td>10,198,000</td><td>13,630,000</td></tr><tr><td>Short Term Investments</td><td>7,189,099</td><td>14,287,000</td><td>21,345,000</td></tr><tr><td>Net Receivables</td><td>2,928,297</td><td>3,845,000</td><td>5,261,000</td></tr><tr><td>Inventory</td><td></td><td></td><td></td></tr><tr><td>Other Current Assets</td><td>1,404,114</td><td>837,000</td><td>1,326,000</td></tr><tr><td>Total Current Assets</td><td>20,178,182</td><td>29,167,000</td><td>41,562,000</td></tr><tr><td>Long Term Investments</td><td>85,160</td><td>129,000</td><td>523,000</td></tr><tr><td>Property Plant and Equipment</td><td>5,233,843</td><td>4,845,000</td><td>7,759,000</td></tr><tr><td>Goodwill</td><td>4,839,854</td><td>4,903,000</td><td>6,256,000</td></tr><tr><td>Intangible Assets</td><td>996,690</td><td>775,000</td><td>1,044,000</td></tr><tr><td>Accumulated Amortization</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Other Assets</td><td>433,846</td><td>415,000</td><td>442,000</td></tr><tr><td>Deferred Long Term Asset Charges</td><td>-</td><td>263,000</td><td>265,000</td></tr><tr><td>Total Assets</td><td>31,767,575</td><td>40,497,000</td><td>57,851,000</td></tr></table>  \n",
            "\n",
            "<|ref|>table<|/ref|><|det|>[[77, 481, 844, 710]]<|/det|>\n",
            "\n",
            "<table><tr><td>Liabilities</td><td></td><td></td><td></td></tr><tr><td>Current Liabilities</td><td></td><td></td><td></td></tr><tr><td>Accounts Payable</td><td>2,084,006</td><td>2,462,000</td><td>6,137,000</td></tr><tr><td>Short/Current Long Term Debt</td><td>-</td><td>-</td><td>3,465,000</td></tr><tr><td>Other Current Liabilities</td><td>218,084</td><td>285,000</td><td>394,000</td></tr><tr><td>Total Current Liabilities</td><td>2,302,090</td><td>2,747,000</td><td>9,996,000</td></tr><tr><td>Long Term Debt</td><td>890,115</td><td>-</td><td>-</td></tr><tr><td>Other Liabilities</td><td>294,175</td><td>1,704,000</td><td>1,579,000</td></tr><tr><td>Deferred Long Term Liability Charges</td><td>42,333</td><td>42,000</td><td>35,000</td></tr><tr><td>Minority Interest</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Negative Goodwill</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Total Liabilities</td><td>3,528,713</td><td>4,493,000</td><td>11,610,000</td></tr></table>  \n",
            "\n",
            "<|ref|>table<|/ref|><|det|>[[77, 727, 844, 920]]<|/det|>\n",
            "\n",
            "<table><tr><td>Stockholders&#x27; Equity</td><td></td><td></td><td></td></tr><tr><td>Misc Stocks Options Warrants</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Redeemable Preferred Stock</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Preferred Stock</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Common Stock</td><td>315</td><td>15,817,000</td><td>18,235,000</td></tr><tr><td>Retained Earnings</td><td>13,561,630</td><td>20,082,000</td><td>27,868,000</td></tr><tr><td>Treasury Stock</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Capital Surplus</td><td>14,450,338</td><td>-</td><td>-</td></tr><tr><td>Other Stockholder Equity</td><td>226,579</td><td>105,000</td><td>138,000</td></tr><tr><td>Total Stockholder Equity</td><td>28,238,862</td><td>36,004,000</td><td>46,241,000</td></tr></table>\n",
            "==================================================\n",
            "image size:  (768, 1024)\n",
            "valid image tokens:  792\n",
            "output texts tokens (valid):  1011\n",
            "compression ratio:  1.28\n",
            "==================================================\n",
            "===============save results:===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 100%|██████████| 6/6 [00:00<00:00, 54120.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Grounding OCR（帶座標）\n",
        "\n",
        "**Prompt：**\n",
        "\n",
        "```python\n",
        "prompt = \"<image>\\n<|grounding|>OCR this image.\"\n",
        "```\n",
        "\n",
        "**最佳用途：**\n",
        "\n",
        "* 需要文字座標資訊\n",
        "* 用於建立標註工具或版面分析\n",
        "\n",
        "**輸出格式：**\n",
        "\n",
        "```\n",
        "<|ref|>The perils of vibe coding<|/ref|><|det|>[[352, 30, 624, 111]]<|/det|>\n",
        "```\n",
        "\n",
        "**輸出檔案：**\n",
        "\n",
        "* `result_with_boxes.jpg`（含邊框）\n",
        "* Console 顯示文字座標"
      ],
      "metadata": {
        "id": "G8KEL-6bqsid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"<image>\\n<|grounding|>OCR this image.\"\n",
        "image_file = '/content/OCRTest.png'\n",
        "output_path = '/content/'\n",
        "\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTbMjQSfqvz7",
        "outputId": "1ae1a1a4-654f-40c0-e651-ce853ec35884"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "<|ref|>Google Inc. (GOOG)<|/ref|><|det|>[[82, 71, 348, 96]]<|/det|>\n",
            "<|ref|>Balance Sheet<|/ref|><|det|>[[82, 102, 220, 120]]<|/det|>\n",
            "<|ref|>All numbers in thousands<|/ref|><|det|>[[588, 104, 797, 121]]<|/det|>\n",
            "<|ref|>Period Ending<|/ref|><|det|>[[80, 142, 190, 160]]<|/det|>\n",
            "<|ref|>Dec31,2008<|/ref|><|det|>[[446, 143, 546, 158]]<|/det|>\n",
            "<|ref|>Dec31,2009<|/ref|><|det|>[[584, 143, 676, 158]]<|/det|>\n",
            "<|ref|>Dec31,2010<|/ref|><|det|>[[700, 143, 797, 158]]<|/det|>\n",
            "<|ref|>Assets<|/ref|><|det|>[[80, 163, 135, 179]]<|/det|>\n",
            "<|ref|>Current Assets<|/ref|><|det|>[[80, 180, 193, 198]]<|/det|>\n",
            "<|ref|>Cash And Cash Equivalents<|/ref|><|det|>[[220, 200, 417, 215]]<|/det|>\n",
            "<|ref|>8,656,672<|/ref|><|det|>[[465, 200, 546, 215]]<|/det|>\n",
            "<|ref|>10,198,000<|/ref|><|det|>[[590, 200, 676, 215]]<|/det|>\n",
            "<|ref|>13,630,000<|/ref|><|det|>[[715, 200, 799, 215]]<|/det|>\n",
            "<|ref|>Short Term Investments<|/ref|><|det|>[[240, 218, 417, 233]]<|/det|>\n",
            "<|ref|>7,189,099<|/ref|><|det|>[[465, 218, 546, 233]]<|/det|>\n",
            "<|ref|>14,287,000<|/ref|><|det|>[[590, 218, 676, 233]]<|/det|>\n",
            "<|ref|>21,345,000<|/ref|><|det|>[[715, 218, 799, 233]]<|/det|>\n",
            "<|ref|>Net Receivables<|/ref|><|det|>[[297, 236, 417, 251]]<|/det|>\n",
            "<|ref|>2,928,297<|/ref|><|det|>[[465, 236, 546, 251]]<|/det|>\n",
            "<|ref|>3,845,000<|/ref|><|det|>[[599, 236, 676, 251]]<|/det|>\n",
            "<|ref|>5,261,000<|/ref|><|det|>[[722, 236, 799, 251]]<|/det|>\n",
            "<|ref|>Inventory<|/ref|><|det|>[[345, 254, 417, 269]]<|/det|>\n",
            "<|ref|>Other Current Assets<|/ref|><|det|>[[260, 272, 417, 287]]<|/det|>\n",
            "<|ref|>1,404,114<|/ref|><|det|>[[465, 272, 546, 287]]<|/det|>\n",
            "<|ref|>837,000<|/ref|><|det|>[[616, 272, 676, 287]]<|/det|>\n",
            "<|ref|>1,326,000<|/ref|><|det|>[[722, 272, 799, 287]]<|/det|>\n",
            "<|ref|>Total Current Assets<|/ref|><|det|>[[80, 291, 232, 306]]<|/det|>\n",
            "<|ref|>20,178,182<|/ref|><|det|>[[456, 291, 546, 306]]<|/det|>\n",
            "<|ref|>29,167,000<|/ref|><|det|>[[590, 291, 676, 306]]<|/det|>\n",
            "<|ref|>41,562,000<|/ref|><|det|>[[715, 291, 799, 306]]<|/det|>\n",
            "<|ref|>Long Term Investments<|/ref|><|det|>[[80, 309, 253, 324]]<|/det|>\n",
            "<|ref|>85,160<|/ref|><|det|>[[483, 309, 546, 324]]<|/det|>\n",
            "<|ref|>129,000<|/ref|><|det|>[[616, 309, 676, 324]]<|/det|>\n",
            "<|ref|>523,000<|/ref|><|det|>[[732, 309, 799, 324]]<|/det|>\n",
            "<|ref|>Property Plant and Equipment<|/ref|><|det|>[[80, 328, 305, 342]]<|/det|>\n",
            "<|ref|>5,233,843<|/ref|><|det|>[[465, 328, 546, 342]]<|/det|>\n",
            "<|ref|>4,845,000<|/ref|><|det|>[[599, 328, 676, 342]]<|/det|>\n",
            "<|ref|>7,759,000<|/ref|><|det|>[[722, 328, 799, 342]]<|/det|>\n",
            "<|ref|>Goodwill<|/ref|><|det|>[[80, 345, 150, 361]]<|/det|>\n",
            "<|ref|>4,839,854<|/ref|><|det|>[[465, 345, 546, 361]]<|/det|>\n",
            "<|ref|>4,903,000<|/ref|><|det|>[[599, 345, 676, 361]]<|/det|>\n",
            "<|ref|>6,256,000<|/ref|><|det|>[[722, 345, 799, 361]]<|/det|>\n",
            "<|ref|>Intangible Assets<|/ref|><|det|>[[80, 364, 211, 379]]<|/det|>\n",
            "<|ref|>996,690<|/ref|><|det|>[[475, 364, 546, 379]]<|/det|>\n",
            "<|ref|>775,000<|/ref|><|det|>[[616, 364, 676, 379]]<|/det|>\n",
            "<|ref|>1,044,000<|/ref|><|det|>[[722, 364, 799, 379]]<|/det|>\n",
            "<|ref|>Accumulated Amortization<|/ref|><|det|>[[80, 383, 280, 397]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[500, 384, 515, 395]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 384, 666, 395]]<|/det|>\n",
            "<|ref|>Other Assets<|/ref|><|det|>[[80, 401, 180, 416]]<|/det|>\n",
            "<|ref|>433,846<|/ref|><|det|>[[475, 401, 546, 416]]<|/det|>\n",
            "<|ref|>415,000<|/ref|><|det|>[[616, 401, 676, 416]]<|/det|>\n",
            "<|ref|>442,000<|/ref|><|det|>[[732, 401, 799, 416]]<|/det|>\n",
            "<|ref|>Deferred Long Term Asset Charges<|/ref|><|det|>[[80, 420, 338, 435]]<|/det|>\n",
            "<|ref|>263,000<|/ref|><|det|>[[616, 420, 676, 435]]<|/det|>\n",
            "<|ref|>265,000<|/ref|><|det|>[[732, 420, 799, 435]]<|/det|>\n",
            "<|ref|>Total Assets<|/ref|><|det|>[[80, 440, 175, 455]]<|/det|>\n",
            "<|ref|>31,767,575<|/ref|><|det|>[[456, 440, 546, 455]]<|/det|>\n",
            "<|ref|>40,497,000<|/ref|><|det|>[[590, 440, 676, 455]]<|/det|>\n",
            "<|ref|>57,851,000<|/ref|><|det|>[[715, 440, 799, 455]]<|/det|>\n",
            "<|ref|>Liabilities<|/ref|><|det|>[[80, 478, 160, 492]]<|/det|>\n",
            "<|ref|>Current Liabilities<|/ref|><|det|>[[80, 497, 214, 512]]<|/det|>\n",
            "<|ref|>Accounts Payable<|/ref|><|det|>[[285, 517, 417, 532]]<|/det|>\n",
            "<|ref|>2,084,006<|/ref|><|det|>[[465, 517, 546, 532]]<|/det|>\n",
            "<|ref|>2,462,000<|/ref|><|det|>[[599, 517, 676, 532]]<|/det|>\n",
            "<|ref|>6,137,000<|/ref|><|det|>[[722, 517, 799, 532]]<|/det|>\n",
            "<|ref|>Short/Current Long Term Debt<|/ref|><|det|>[[190, 535, 417, 550]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[500, 537, 515, 548]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 537, 666, 548]]<|/det|>\n",
            "<|ref|>3,465,000<|/ref|><|det|>[[722, 535, 799, 550]]<|/det|>\n",
            "<|ref|>Other Current Liabilities<|/ref|><|det|>[[240, 554, 417, 568]]<|/det|>\n",
            "<|ref|>218,084<|/ref|><|det|>[[475, 554, 546, 568]]<|/det|>\n",
            "<|ref|>285,000<|/ref|><|det|>[[616, 554, 676, 568]]<|/det|>\n",
            "<|ref|>394,000<|/ref|><|det|>[[732, 554, 799, 568]]<|/det|>\n",
            "<|ref|>Total Current Liabilities<|/ref|><|det|>[[80, 573, 258, 588]]<|/det|>\n",
            "<|ref|>2,302,090<|/ref|><|det|>[[465, 573, 546, 588]]<|/det|>\n",
            "<|ref|>2,747,000<|/ref|><|det|>[[599, 573, 676, 588]]<|/det|>\n",
            "<|ref|>9,996,000<|/ref|><|det|>[[715, 573, 799, 588]]<|/det|>\n",
            "<|ref|>Long Term Debt<|/ref|><|det|>[[80, 592, 201, 607]]<|/det|>\n",
            "<|ref|>890,115<|/ref|><|det|>[[475, 592, 546, 607]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 593, 666, 604]]<|/det|>\n",
            "<|ref|>Other Liabilities<|/ref|><|det|>[[80, 610, 201, 625]]<|/det|>\n",
            "<|ref|>294,175<|/ref|><|det|>[[475, 610, 546, 625]]<|/det|>\n",
            "<|ref|>1,704,000<|/ref|><|det|>[[599, 610, 676, 625]]<|/det|>\n",
            "<|ref|>1,579,000<|/ref|><|det|>[[715, 610, 799, 625]]<|/det|>\n",
            "<|ref|>Deferred Long Term Liability Charges<|/ref|><|det|>[[80, 628, 354, 645]]<|/det|>\n",
            "<|ref|>42,333<|/ref|><|det|>[[483, 628, 546, 643]]<|/det|>\n",
            "<|ref|>42,000<|/ref|><|det|>[[616, 628, 676, 643]]<|/det|>\n",
            "<|ref|>35,000<|/ref|><|det|>[[740, 628, 799, 643]]<|/det|>\n",
            "<|ref|>Minority Interest<|/ref|><|det|>[[80, 647, 211, 662]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[500, 649, 515, 660]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 649, 666, 660]]<|/det|>\n",
            "<|ref|>Negative Goodwill<|/ref|><|det|>[[80, 666, 220, 681]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[500, 668, 515, 679]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 668, 666, 679]]<|/det|>\n",
            "<|ref|>Total Liabilities<|/ref|><|det|>[[80, 685, 200, 700]]<|/det|>\n",
            "<|ref|>3,528,713<|/ref|><|det|>[[465, 685, 546, 700]]<|/det|>\n",
            "<|ref|>4,493,000<|/ref|><|det|>[[599, 685, 676, 700]]<|/det|>\n",
            "<|ref|>11,610,000<|/ref|><|det|>[[715, 685, 799, 700]]<|/det|>\n",
            "<|ref|>Stockholders'Equity<|/ref|><|det|>[[80, 724, 238, 739]]<|/det|>\n",
            "<|ref|>Misc Stocks Options Warrants<|/ref|><|det|>[[80, 743, 303, 758]]<|/det|>\n",
            "<|ref|>Redeemable Preferred Stock<|/ref|><|det|>[[80, 761, 290, 776]]<|/det|>\n",
            "<|ref|>Preferred Stock<|/ref|><|det|>[[80, 780, 201, 795]]<|/det|>\n",
            "<|ref|>Common Stock<|/ref|><|det|>[[80, 799, 195, 814]]<|/det|>\n",
            "<|ref|>315<|/ref|><|det|>[[512, 799, 546, 814]]<|/det|>\n",
            "<|ref|>15,817,000<|/ref|><|det|>[[590, 799, 676, 814]]<|/det|>\n",
            "<|ref|>18,235,000<|/ref|><|det|>[[715, 799, 799, 814]]<|/det|>\n",
            "<|ref|>Retained Earnings<|/ref|><|det|>[[80, 817, 217, 832]]<|/det|>\n",
            "<|ref|>13,561,630<|/ref|><|det|>[[456, 817, 546, 832]]<|/det|>\n",
            "<|ref|>20,082,000<|/ref|><|det|>[[590, 817, 676, 832]]<|/det|>\n",
            "<|ref|>27,868,000<|/ref|><|det|>[[715, 817, 799, 832]]<|/det|>\n",
            "<|ref|>Treasury Stock<|/ref|><|det|>[[80, 836, 195, 851]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[500, 837, 515, 848]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 837, 666, 848]]<|/det|>\n",
            "<|ref|>Capital Surplus<|/ref|><|det|>[[80, 854, 195, 869]]<|/det|>\n",
            "<|ref|>14,450,338<|/ref|><|det|>[[456, 854, 546, 869]]<|/det|>\n",
            "<|ref|>-<|/ref|><|det|>[[650, 855, 666, 867]]<|/det|>\n",
            "<|ref|>Other Stockholder Equity<|/ref|><|det|>[[80, 873, 266, 888]]<|/det|>\n",
            "<|ref|>226,579<|/ref|><|det|>[[475, 873, 546, 888]]<|/det|>\n",
            "<|ref|>105,000<|/ref|><|det|>[[616, 873, 676, 888]]<|/det|>\n",
            "<|ref|>138,000<|/ref|><|det|>[[732, 873, 799, 888]]<|/det|>\n",
            "<|ref|>Total Stockholder Equity<|/ref|><|det|>[[80, 892, 266, 907]]<|/det|>\n",
            "<|ref|>28,238,862<|/ref|><|det|>[[456, 892, 546, 907]]<|/det|>\n",
            "<|ref|>36,004,000<|/ref|><|det|>[[590, 892, 676, 907]]<|/det|>\n",
            "<|ref|>46,241,000<|/ref|><|det|>[[715, 892, 799, 907]]<|/det|>\n",
            "==================================================\n",
            "image size:  (768, 1024)\n",
            "valid image tokens:  792\n",
            "output texts tokens (valid):  2591\n",
            "compression ratio:  3.27\n",
            "==================================================\n",
            "===============save results:===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 100%|██████████| 125/125 [00:00<00:00, 160479.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Detailed Description（影像分析）\n",
        "\n",
        "**Prompt：**\n",
        "\n",
        "```python\n",
        "prompt = \"<image>\\nDescribe this image in detail.\"\n",
        "```\n",
        "\n",
        "**最佳用途：**\n",
        "\n",
        "* 影像語意分析\n",
        "* 內容理解或版面描述\n",
        "\n",
        "**輸出格式：**\n",
        "\n",
        "* 以自然語言描述影像內容\n",
        "* 非OCR為主\n",
        "\n",
        "**範例：**\n",
        "\n",
        "```\n",
        "The image displays a printed page from a publication,\n",
        "likely a magazine or a book...\n",
        "```"
      ],
      "metadata": {
        "id": "MJAn-QxGqwOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" <image>\\nDescribe this image in detail.\"\n",
        "image_file = '/content/OCRTest.png'\n",
        "output_path = '/content/'\n",
        "\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOaA0YlXB4Pk",
        "outputId": "4b4f47cf-24d1-4fab-cdfd-f864292b9fcd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "This image displays a table with 31 rows and 9 columns. The first column is labeled \"Period Ending\", the second column is labeled \"Dec 31, 2008\", the third column is labeled \"Dec 31, 2009\", and the fourth column is labeled \"Dec 31, 2010\". The fifth column is labeled \"Assets\", the sixth column is labeled \"Current Assets\", the seventh column is labeled \"Long Term Investments\", the eighth column is labeled \"Property Plant and Equipment\", the ninth column is labeled \"Goodwill\", the tenth column is labeled \"Intangible Assets\", the eleventh column is labeled \"Accumulated Amortization\", the twelfth column is labeled \"Other Assets\", the thirteenth column is labeled \"Deferred Long Term Assets\", and the fourteenth column is labeled \"Total Assets\". The table is titled \"Google Inc. (GOOG) Balance Sheet\". The image is a screenshot of a spreadsheet.\n",
            "==================================================\n",
            "image size:  (768, 1024)\n",
            "valid image tokens:  792\n",
            "output texts tokens (valid):  192\n",
            "compression ratio:  0.24\n",
            "==================================================\n",
            "===============save results:===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#第五章、其他數據"
      ],
      "metadata": {
        "id": "SlgTU5_Jvumz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 影像尺寸大小\n",
        "\n",
        "| 模式名稱           | base_size | image_size | crop_mode | Token數 | 特性            |\n",
        "| -------------- | --------- | ---------- | --------- | ------ | ------------- |\n",
        "| Tiny           | 512       | 512        | False     | ~64    | 最快            |\n",
        "| Small          | 640       | 640        | False     | ~100   | 快速            |\n",
        "| Base           | 1024      | 1024       | False     | ~256   | 平衡            |\n",
        "| Large          | 1280      | 1280       | False     | ~400   | 高品質           |\n",
        "| **Gundam（推薦）** | 1024      | 640        | True      | 356+   | 動態裁切、最佳化速度與品質 |\n"
      ],
      "metadata": {
        "id": "PzgDVxeLsGPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 實用建議\n",
        "\n",
        "1. 選對 Prompt\n",
        "- 要文字 → Free OCR\n",
        "- 要文件格式 → Markdown\n",
        "- 要座標資訊 → Grounding OCR\n",
        "- 要影像內容 → Detailed\n",
        "\n",
        "2. 影像尺寸調整\n",
        "\n",
        "- 大圖 → Gundam 模式 (crop_mode=True)\n",
        "- 小圖 → 適當 base_size (512/640)\n",
        "- 速度優先 → 小尺寸\n",
        "- 品質優先 → 大尺寸\n",
        "\n",
        "3. 後處理建議\n",
        "- Free OCR：文字流暢但可能略有斷行問題\n",
        "- Markdown：結構較完整\n",
        "- 複雜版面 → 可能需手動清理"
      ],
      "metadata": {
        "id": "-j006odGr0_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 常見問題\n",
        "\n",
        "| 問題               | 原因        | 解決方式                          |\n",
        "| ---------------- | --------- | ----------------------------- |\n",
        "| `result.mmd` 為空白 | 模型未辨識出內容  | 改用 \"Free OCR\" 或 \"Markdown\"    |\n",
        "| 文字流不順            | OCR 分段不理想 | 調整 `crop_mode` 或更換 Prompt     |\n",
        "| 缺字/漏行            | 圖像品質或尺寸不足 | 提高 `image_size` / `base_size` |\n"
      ],
      "metadata": {
        "id": "Vidq0uM5sBX6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpjeiC8drh3n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}